{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, utils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg_preloaded(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, use_cuda):\n",
    "        super(vgg_preloaded, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.num_class = num_class\n",
    "        self.dtype = torch.cuda.FloatTensor if self.use_cuda else torch.FloatTensor\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        self.model = model.cuda() if self.use_cuda else model\n",
    "        self.model.classifier.require_grad = True\n",
    "        self.model.features.require_grad = True\n",
    "        \n",
    "\n",
    "    def forward(self, inp):\n",
    "        return(self.model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Below is the data loader\n",
    "#----------------------------------------------------\n",
    "\n",
    "\n",
    "class MelaData(Dataset):\n",
    "\t\"\"\"MelaData dataset.\"\"\"\n",
    "\n",
    "\tdef __init__(self, data_dir, label_csv, transform=None):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tcsv_file (string): Path to the csv file with labels.\n",
    "\t\t\tdata_dir (string): Directory with all the images.\n",
    "\t\t\ttransform (callable, optional): Optional transform to be applied on a sample: use prep1\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tself.data_dir = data_dir\n",
    "\t\tself.files = os.listdir(data_dir)\n",
    "\n",
    "\t\tlabels = pd.read_csv(label_csv)\n",
    "\t\tdx_to_num = {'nv' : 0, 'mel': 1, 'bkl': 2, 'df': 3, 'akiec': 4, 'bcc': 5, 'vasc' : 6}        \n",
    "\t\tlabels['label'] = labels['dx'].apply(lambda x: dx_to_num[x])\n",
    "\t\tself.labels = labels\n",
    "\n",
    "\t\tif transform is None:\n",
    "\t\t\tnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\t\t\ttransform = transforms.Compose([\n",
    "\t\t\t\ttransforms.Resize(224),\n",
    "\t\t\t\ttransforms.CenterCrop(224),\n",
    "\t\t\t\ttransforms.ColorJitter(hue=.05, saturation=.05),\n",
    "\t\t\t\ttransforms.RandomHorizontalFlip(),\n",
    "\t\t\t\ttransforms.RandomRotation(360, resample=Image.BILINEAR),\n",
    "\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t\tnormalize,\n",
    "\t\t\t\t])\n",
    "\n",
    "\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.files)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage_name_with_extension = self.files[idx]\n",
    "\t\timage = Image.open(self.data_dir + image_name_with_extension)\n",
    "\t\timage_name = image_name_with_extension.strip('.jpg')\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image)    \n",
    "\n",
    "\t\tlabel = self.labels.loc[self.labels['image_id'] == image_name, 'label']\n",
    "\t\tlabel = np.array(label)\n",
    "\t\tlabel_t = torch.from_numpy(label)[0]\n",
    "\t\treturn(image, label_t)\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Below is the data splitter\n",
    "#----------------------------------------------------\n",
    "\n",
    "\n",
    "def train_val_test_split(dataset, train_split, val_split, test_split):\n",
    "\t\"\"\"\n",
    "\tSplit data set into training, validation, and test sets.\n",
    "\t\"\"\"\n",
    "\t#if train_split + val_split + test_split != 1:\n",
    "\t\t#print('Incorrect split sizes')\n",
    "\n",
    "\t# Size of data set\n",
    "\tN = dataset.__len__()\n",
    "\n",
    "\t# Size of train set\n",
    "\ttrain_size = math.floor(train_split * N)\n",
    "\n",
    "\t# Size of validation set\n",
    "\tval_size = math.floor(val_split * N)\n",
    "\n",
    "\t# List of all data indices\n",
    "\tindices = list(range(N))\n",
    "\n",
    "\t# Random selection of indices for train set\n",
    "\ttrain_ids = np.random.choice(indices, size=train_size, replace=False)\n",
    "\ttrain_ids = list(train_ids)\n",
    "\n",
    "\t# Deletion of indices used for train set\n",
    "\tindices = list(set(indices) - set(train_ids))\n",
    "\n",
    "\t# Random selection of indices for validation set\n",
    "\tval_ids = np.random.choice(indices, size=val_size, replace=False)\n",
    "\tval_ids = list(val_ids)\n",
    "\n",
    "\t# Selecting remaining indices for test set\n",
    "\ttest_ids = list(set(indices) - set(val_ids))\n",
    "\n",
    "\t# Creating subsets\n",
    "\ttrain_data = torch.utils.data.Subset(dataset, train_ids)\n",
    "\tval_data = torch.utils.data.Subset(dataset, val_ids)\n",
    "\ttest_data = torch.utils.data.Subset(dataset, test_ids)\n",
    "\treturn(train_data, val_data, test_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Below is the train function\n",
    "#----------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def train(data_dir, label_dir, save_dir, epoch, mb, num_class, num_workers = 1, use_cuda = False, conti = False, lr = 1e-3, save = True, name = None, train_prop = 0.7):\n",
    "\t# instantiate the vgg model\n",
    "\tmodel = vgg_preloaded(num_class, use_cuda)\n",
    "\n",
    "\tif name is None:\n",
    "\t\tname = 'model'\n",
    "\n",
    "\t# if dir does not exit, make it:\n",
    "\tif not os.path.isdir(save_dir):\n",
    "\t\tos.mkdir(save_dir)\n",
    "\n",
    "\t# define model path\n",
    "\tmodelpath = os.path.join(save_dir, '{}.pt'.format(name))\n",
    "\n",
    "\t# do we wanna continue to train\n",
    "\tif os.path.isfile(modelpath) and conti:\n",
    "\t\tmodel.load_state_dict(torch.load(modelpath))\n",
    "\tif use_cuda:\n",
    "\t\tmodel = model.cuda()\n",
    "\tmodel.train()\n",
    "\n",
    "\tloss_train = np.zeros(epoch)\n",
    "\tacc_train = np.zeros(epoch)\n",
    "\tloss_fun = torch.nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\toptim = Adam(model.parameters(), lr = lr)\n",
    "\tdataset = MelaData(data_dir = data_dir, label_csv = label_dir)\n",
    "\tval_prop = 1 - train_prop\n",
    "\ttrain_data, val_data, test_data = train_val_test_split(dataset, train_prop, val_prop, 0.0)\n",
    "\n",
    "\tfor epoch_num in range(1, epoch+1):\n",
    "\t\trunning_loss = 0.0\n",
    "\t\trunning_corrects = 0.0\n",
    "\t\tsize = 0\n",
    "\n",
    "\t\tdataloader = DataLoader(train_data, batch_size = mb, shuffle = True, num_workers = num_workers)\n",
    "\n",
    "\t\tpbar = tqdm(dataloader)\n",
    "\t\tpbar.set_description(\"[Epoch {}]\".format(epoch_num))\n",
    "\t\tfor inputs, labels in pbar:\n",
    "\t\t\tbs = labels.size(0)\n",
    "\t\t\tif use_cuda:\n",
    "\t\t\t\tinputs = inputs.cuda()\n",
    "\t\t\t\tlabels = labels.cuda()\n",
    "\t\t\toutput = model(inputs)\n",
    "\t\t\t_, preds = torch.max(output.data, 1)\n",
    "\t\t\tloss = loss_fun(output, labels)\n",
    "\t\t\trunning_loss += loss\n",
    "\t\t\trunning_corrects += preds.eq(labels.view_as(preds)).sum()\n",
    "\t\t\toptim.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptim.step()\n",
    "\t\t\tsize += bs\n",
    "\n",
    "\t\tepoch_loss = running_loss / size\n",
    "\t\tepoch_acc = running_corrects.item() / size\n",
    "\t\tloss_train[epoch_num-1] = epoch_loss\n",
    "\t\tacc_train[epoch_num-1] = epoch_acc\n",
    "\t\tprint('Train - Loss: {:.4F} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\tif save:\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(save_dir, '{}.pt'.format(name)))\n",
    "\t\ttorch.save(optim.state_dict(), os.path.join(save_dir, '{}.optim.pt'.format(name)))\n",
    "\treturn(loss_train, acc_train, val_data)\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Below is the eval function\n",
    "#----------------------------------------------------\n",
    "def test_model(model_dir, val_data, label_dir, batch_size, num_workers = 1, use_cuda = False):\n",
    "\tmodel = vgg_preloaded(7, use_cuda=use_cuda)\n",
    "\tmodel.load_state_dict(torch.load(model_dir))\n",
    "\tmodel = model.cuda() if use_cuda else model\n",
    "\n",
    "\t#dataset = MelaData(data_dir = data_dir, label_csv = label_dir)\n",
    "\tdataloader = DataLoader(val_data, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n",
    "\tloss_fn = torch.nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "\tmodel.eval()\n",
    "\tpredictions = [] #Store predictions in here\n",
    "\tclass_list = [] #store ground truth here\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\trunning_corrects = 0\n",
    "\tcount = 0\n",
    "\n",
    "\tpbar = tqdm(dataloader)\n",
    "\tpbar.set_description(\"[Epoch {}]\".format('Validation'))\n",
    "\tfor inputs,classes in pbar:\n",
    "\t\tif use_cuda:\n",
    "\t\t\tinputs = inputs.cuda()\n",
    "\t\t\tclasses = classes.cuda()\n",
    "\t\telse:\n",
    "\t\t\tinputs = inputs\n",
    "\t\t\tclasses = classes\n",
    "\t\toutputs = model(inputs)\n",
    "\t\tloss = loss_fn(outputs,classes) \n",
    "\t\t_,preds = torch.max(outputs.data, 1)\n",
    "\t\trunning_loss += loss.cpu().data.item()\n",
    "\t\trunning_corrects += preds.eq(classes.view_as(preds)).sum()\n",
    "\t\tpredictions += list(preds.cpu().data.numpy())\n",
    "\t\tif use_cuda:\n",
    "\t\t\tclass_save = classes.cpu().data.numpy()\n",
    "\t\telse:\n",
    "\t\t\tclass_save = classes.data.numpy()\n",
    "\t\tclass_list.append(class_save)\n",
    "\t\tcount +=1\n",
    "\n",
    "\tprint('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / len(val_data), running_corrects.data.item() / len(val_data)))\n",
    "\treturn({'loss': running_loss / len(val_data), 'acc': running_corrects.data.item() / len(val_data), 'predictions': predictions, 'classes': class_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_images_part_1/'\n",
    "label_dir = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n",
    "save_dir = '/home/paperspace/projects/skin_cancer/data/res_model/'\n",
    "epoch = 2\n",
    "mb = 4\n",
    "num_class = 7\n",
    "num_workers = 1\n",
    "cuda = True\n",
    "conti = False\n",
    "save = True\n",
    "name = 'test_model'\n",
    "lr = 1e-3\n",
    "stage = 'transfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 1753/1753 [04:29<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.1388 Acc: 0.6722\n"
     ]
    }
   ],
   "source": [
    "loss_train, acc_train, val_data = train(data_dir = data_d, label_dir = label_dir, save_dir = save_dir, epoch = epoch, mb = mb, num_class = num_class, num_workers = num_workers, use_cuda = cuda, conti = conti, lr = lr, save = True, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch Validation]: 100%|██████████| 251/251 [00:56<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1703 Acc: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "model_dir = '/home/paperspace/projects/skin_cancer/data/res_model/model.pt'\n",
    "val_data = val_data\n",
    "label_dir = None\n",
    "batch_size = 1\n",
    "use_cuda = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "res = test_model(model_dir = model_dir, val_data = val_data, label_dir = label_dir, batch_size = 12, use_cuda = use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3004})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(res['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
