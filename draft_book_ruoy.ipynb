{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_path = '../data/res_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_meta = pd.read_csv(data_path + 'HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confocal', 'consensus', 'follow_up', 'histo'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd_meta.dx_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to data description, only the 'follow-up' category is confirmed and therefore can be used as positive label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd_meta.dx_type == 'follow_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd_meta.dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data description, the above categories correpond to the following diagnoses:\n",
    "- Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec)\n",
    "- basal cell carcinoma (bcc)\n",
    "- benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl)\n",
    "- dermatofibroma (df)\n",
    "- melanoma (mel)\n",
    "- melanocytic nevi (nv) \n",
    "- vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have about 3.7k positive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_28 = pd.read_csv(data_path+'hmnist_28_28_RGB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "5        2\n",
       "6        2\n",
       "7        2\n",
       "8        2\n",
       "9        2\n",
       "10       2\n",
       "11       2\n",
       "12       2\n",
       "13       2\n",
       "14       2\n",
       "15       2\n",
       "16       2\n",
       "17       2\n",
       "18       2\n",
       "19       2\n",
       "20       2\n",
       "21       2\n",
       "22       2\n",
       "23       2\n",
       "24       2\n",
       "25       2\n",
       "26       2\n",
       "27       2\n",
       "28       2\n",
       "29       2\n",
       "        ..\n",
       "9985     0\n",
       "9986     0\n",
       "9987     0\n",
       "9988     0\n",
       "9989     0\n",
       "9990     0\n",
       "9991     0\n",
       "9992     0\n",
       "9993     0\n",
       "9994     0\n",
       "9995     0\n",
       "9996     0\n",
       "9997     0\n",
       "9998     0\n",
       "9999     0\n",
       "10000    0\n",
       "10001    0\n",
       "10002    0\n",
       "10003    0\n",
       "10004    0\n",
       "10005    0\n",
       "10006    0\n",
       "10007    0\n",
       "10008    0\n",
       "10009    0\n",
       "10010    0\n",
       "10011    0\n",
       "10012    0\n",
       "10013    0\n",
       "10014    6\n",
       "Name: label, Length: 10015, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_28.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.zeros((1, 5), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot[0][3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.from_numpy(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_output = np.array([[1,2,3], [2,3,4], [2,3,4], [3,4,5], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_output = torch.from_numpy(pseudo_output).float().t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 2., 3., 4.],\n",
       "        [2., 3., 3., 4., 5.],\n",
       "        [3., 4., 4., 5., 6.]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(one_hot*pseudo_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4., 5.]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(one_hot, pseudo_output.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16 = models.vgg16(pretrained = True)\n",
    "model_vgg19 = models.vgg19(pretrained = True)\n",
    "\n",
    "model_vgg16.eval()\n",
    "model_vgg19.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "1 ReLU(inplace)\n",
      "2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "3 ReLU(inplace)\n",
      "4 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "5 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "6 ReLU(inplace)\n",
      "7 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "8 ReLU(inplace)\n",
      "9 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "10 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "11 ReLU(inplace)\n",
      "12 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "13 ReLU(inplace)\n",
      "14 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "15 ReLU(inplace)\n",
      "16 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "17 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "18 ReLU(inplace)\n",
      "19 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "20 ReLU(inplace)\n",
      "21 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "22 ReLU(inplace)\n",
      "23 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "24 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "25 ReLU(inplace)\n",
      "26 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "27 ReLU(inplace)\n",
      "28 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "29 ReLU(inplace)\n",
      "30 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model_vgg.features._modules.items():\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.randn(1,1)\n",
    "xx.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6389]], requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = 4 * xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = yy**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f1787030390>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_grad = []\n",
    "def return_grad(grad):\n",
    "    yy_grad.append(grad)\n",
    "yy.register_hook(return_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20.4462]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-5.1116]])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "\tmeans=[0.485, 0.456, 0.406]\n",
    "\tstds=[0.229, 0.224, 0.225]\n",
    "\n",
    "\tpreprocessed_img = img.copy()[: , :, ::-1]\n",
    "\tfor i in range(3):\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "\tpreprocessed_img = \\\n",
    "\t\tnp.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "\tpreprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "\tpreprocessed_img.unsqueeze_(0)\n",
    "\t#input = Variable(preprocessed_img, requires_grad = True)\n",
    "\tinput = preprocessed_img\n",
    "\tinput.requires_grad = True\n",
    "\treturn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractFeatures:\n",
    "\t\"\"\"\n",
    "\tClass for mannually passing the input image through the model\n",
    "\tthe gradient at the identified layer will be registered and saved\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, model, target_layer):\n",
    "\t\tself.model = model\n",
    "\t\tself.target_layer = target_layer\n",
    "\t\tself.gradients = []\n",
    "\n",
    "\tdef save_grad(self, grad):\n",
    "\t\tself.gradients.append(grad)\n",
    "\n",
    "\tdef record_and_feed_forward(self, inp):\n",
    "\t\t# we want to reset the gradient every time we call the method\n",
    "\t\tself.gradients = []\n",
    "\t\tlayer_output = None\n",
    "\t\tprint(self.model.features)\n",
    "\t\tfor name, layer in self.model.features._modules.items():\n",
    "\t\t\t# here we mannually pass the input through the NN until the identified layer\n",
    "\t\t\tinp = layer(inp)\n",
    "\t\t\tprint(name)\n",
    "\t\t\tif name[0] == self.target_layer:\n",
    "\t\t\t\tprint('yes')\n",
    "\t\t\t\t# here by registering the hook, we tag the layer and notify torch that we want to keep the gradient for this layer\n",
    "\t\t\t\tinp.register_hook(self.save_grad)\n",
    "\t\t\t\t# record the output at the identified layer, the output is the same as the input for the next layer (activation: final ReLU for VGG before classif)\n",
    "\t\t\t\tlayer_output = inp\n",
    "\t\t# need to flatten before the fully connected layers in the classifier half\n",
    "\t\tinp = inp.view(inp.size(0), -1)\n",
    "\t\t# classify\n",
    "\t\tinp = self.model.classifier(inp)\n",
    "\t\treturn(layer_output, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_pretrained import vgg_preloaded, MelaData, train, train_val_test_split, test_model\n",
    "import pickle\n",
    "import torch\n",
    "from class_activation_map import ExtractFeatures, GradCam\n",
    "\n",
    "save_dir = '/home/paperspace/projects/skin_cancer/data/res_model/'\n",
    "model_name = 'test_model_100_loss_0_1995_acc_0_9248.pt'\n",
    "name = save_dir + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_preloaded(7, use_cuda = True)\n",
    "model.load_state_dict(torch.load(name))\n",
    "model.model.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for name, mod in model.model.features._modules.items():\n",
    "    print(name == target_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = '29'\n",
    "feature_extractor = ExtractFeatures(model.model, target_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0025713.jpg'\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = preprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = inp.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "act, output = feature_extractor.record_and_feed_forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace)\n",
       "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (24): ReLU(inplace)\n",
       "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (26): ReLU(inplace)\n",
       "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (31): ReLU(inplace)\n",
       "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (35): ReLU(inplace)\n",
       "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg19.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 7, 7])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25088])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(output.size(0),-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n"
     ]
    }
   ],
   "source": [
    "print('hi') if a is None else print('lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act[-1].cpu().data.numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act[-1].cpu().data.numpy()[0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractfeatures = ExtractFeatures(model_vgg16, '29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, output = extractfeatures.record_and_feed_forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code = np.argmax(output.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)\n",
    "one_hot[0][class_code] = 1\n",
    "one_hot = torch.from_numpy(one_hot)\n",
    "one_hot.requires_grad = True\n",
    "one_hot = one_hot.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_value = torch.sum(torch.mm(one_hot, output.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_value = output[0][class_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.6454, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.features.zero_grad()\n",
    "model_vgg16.classifier.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_value.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = extractfeatures.gradients[-1].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 14, 14)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = np.mean(grads, axis = (2,3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = feature.cpu().data.numpy()[0] # in case the input target_layer is multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = np.zeros(target_layer.shape[1 : ], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(grads):\n",
    "    cam += w * target_layer[i, :, :]\n",
    "cam = np.maximum(cam, 0)\n",
    "cam = cv2.resize(cam, (600, 450))\n",
    "cam = cam - np.min(cam)\n",
    "cam = cam / np.max(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0025713.jpg'\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "#img = np.float32(img) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 600, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "cam_ = heatmap + np.float32(img)\n",
    "cam_ = cam_ / np.max(cam_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', cam_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"cam.jpg\", np.uint8(255 * cam_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189, 189, 189, ...,  89,  89,  89],\n",
       "       [189, 189, 189, ...,  89,  89,  89],\n",
       "       [189, 189, 189, ...,  89,  89,  89],\n",
       "       ..., \n",
       "       [226, 226, 226, ..., 255, 255, 255],\n",
       "       [226, 226, 226, ..., 255, 255, 255],\n",
       "       [226, 226, 226, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.uint8(255*cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_pretrained import vgg_preloaded, MelaData, train, train_val_test_split, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (vgg_transfer_learning_version.py, line 141)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-fb3189dddc73>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from vgg_transfer_learning_version import vgg_preloaded, MelaData, train, train_val_test_split\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/paperspace/projects/skin_cancer/Skin_Cancer_Detection/vgg_transfer_learning_version.py\"\u001b[0;36m, line \u001b[0;32m141\u001b[0m\n\u001b[0;31m    return(train_data, val_data, test_data)\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from vgg_transfer_learning_version import vgg_preloaded, MelaData, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, utils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_images_part_1/'\n",
    "label_dir = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n",
    "save_dir = '/home/paperspace/projects/skin_cancer/data/res_model/'\n",
    "epoch = 5\n",
    "mb = 24\n",
    "num_class = 7\n",
    "num_workers = 1\n",
    "cuda = True\n",
    "conti = False\n",
    "save = True\n",
    "name = 'test_model'\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 293/293 [02:35<00:00,  1.88it/s]\n",
      "[Epoch 2]:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8592 Acc: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 293/293 [02:36<00:00,  1.87it/s]\n",
      "[Epoch 3]:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7120 Acc: 0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 293/293 [02:36<00:00,  1.87it/s]\n",
      "[Epoch 4]:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6427 Acc: 0.7649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|██████████| 293/293 [02:36<00:00,  1.88it/s]\n",
      "[Epoch 5]:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6117 Acc: 0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|██████████| 293/293 [02:36<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.5698 Acc: 0.7983\n"
     ]
    }
   ],
   "source": [
    "res = train(data_dir = data_d, label_dir = label_dir, save_dir = save_dir, epoch = epoch, mb = mb, num_class = num_class, num_workers = num_workers, use_cuda = cuda, conti = conti, lr = lr, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(dataset, train_split, val_split, test_split):\n",
    "\t\"\"\"\n",
    "\tSplit data set into training, validation, and test sets.\n",
    "\t\"\"\"\n",
    "\t#if train_split + val_split + test_split != 1:\n",
    "\t\t#print('Incorrect split sizes')\n",
    "\n",
    "\t# Size of data set\n",
    "\tN = dataset.__len__()\n",
    "\n",
    "\t# Size of train set\n",
    "\ttrain_size = math.floor(train_split * N)\n",
    "\n",
    "\t# Size of validation set\n",
    "\tval_size = math.floor(val_split * N)\n",
    "\n",
    "\t# List of all data indices\n",
    "\tindices = list(range(N))\n",
    "\n",
    "\t# Random selection of indices for train set\n",
    "\ttrain_ids = np.random.choice(indices, size=train_size, replace=False)\n",
    "\ttrain_ids = list(train_ids)\n",
    "\n",
    "\t# Deletion of indices used for train set\n",
    "\tindices = list(set(indices) - set(train_ids))\n",
    "\n",
    "\t# Random selection of indices for validation set\n",
    "\tval_ids = np.random.choice(indices, size=val_size, replace=False)\n",
    "\tval_ids = list(val_ids)\n",
    "\n",
    "\t# Selecting remaining indices for test set\n",
    "\ttest_ids = list(set(indices) - set(val_ids))\n",
    "\n",
    "\t# Creating subsets\n",
    "\ttrain_data = torch.utils.data.Subset(dataset, train_ids)\n",
    "\tval_data = torch.utils.data.Subset(dataset, val_ids)\n",
    "\ttest_data = torch.utils.data.Subset(dataset, test_ids)\n",
    "\treturn(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, label_dir, save_dir, epoch, mb, num_class, num_workers = 1, use_cuda = False, conti = False, lr = 1e-3, save = True, name = None, train_prop = 0.7):\n",
    "\t# instantiate the vgg model\n",
    "\tmodel = vgg_preloaded(num_class, use_cuda)\n",
    "\n",
    "\tif name is None:\n",
    "\t\tname = 'model'\n",
    "\n",
    "\t# if dir does not exit, make it:\n",
    "\tif not os.path.isdir(save_dir):\n",
    "\t\tos.mkdir(save_dir)\n",
    "\n",
    "\t# define model path\n",
    "\tmodelpath = os.path.join(save_dir, '{}.pt'.format(name))\n",
    "\n",
    "\t# do we wanna continue to train\n",
    "\tif os.path.isfile(modelpath) and conti:\n",
    "\t\tmodel.load_state_dict(torch.load(modelpath))\n",
    "\tif use_cuda:\n",
    "\t\tmodel = model.cuda()\n",
    "\tmodel.train()\n",
    "\n",
    "\tloss_train = np.zeros(epoch)\n",
    "\tacc_train = np.zeros(epoch)\n",
    "\tloss_fun = torch.nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\toptim = Adam(model.parameters(), lr = lr)\n",
    "\tdataset = MelaData(data_dir = data_dir, label_csv = label_dir)\n",
    "\tval_prop = 1 - train_prop\n",
    "\ttrain_data, val_data, test_data = train_val_test_split(dataset, train_prop, val_prop, 0.0)\n",
    "\n",
    "\tfor epoch_num in range(1, epoch+1):\n",
    "\t\trunning_loss = 0.0\n",
    "\t\trunning_corrects = 0.0\n",
    "\t\tsize = 0\n",
    "\n",
    "\t\tdataloader = DataLoader(train_data, batch_size = mb, shuffle = True, num_workers = num_workers)\n",
    "\n",
    "\t\tpbar = tqdm(dataloader)\n",
    "\t\tpbar.set_description(\"[Epoch {}]\".format(epoch_num))\n",
    "\t\tfor inputs, labels in pbar:\n",
    "\t\t\tbs = labels.size(0)\n",
    "\t\t\tif use_cuda:\n",
    "\t\t\t\tinputs = inputs.cuda()\n",
    "\t\t\t\tlabels = labels.cuda()\n",
    "\t\t\toutput = model(inputs)\n",
    "\t\t\t_, preds = torch.max(output.data, 1)\n",
    "\t\t\tloss = loss_fun(output, labels)\n",
    "\t\t\trunning_loss += loss\n",
    "\t\t\trunning_corrects += preds.eq(labels.view_as(preds)).sum()\n",
    "\t\t\toptim.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptim.step()\n",
    "\t\t\tsize += bs\n",
    "\n",
    "\t\tepoch_loss = running_loss / size\n",
    "\t\tepoch_acc = running_corrects.item() / size\n",
    "\t\tloss_train[epoch_num-1] = epoch_loss\n",
    "\t\tacc_train[epoch_num-1] = epoch_acc\n",
    "\t\tprint('Train - Loss: {:.4F} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\tif save:\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(save_dir, '{}.pt'.format(name)))\n",
    "\t\ttorch.save(optim.state_dict(), os.path.join(save_dir, '{}.optim.pt'.format(name)))\n",
    "\treturn(loss_train, acc_train, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-211f1f2a8a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/skin_cancer/Skin_Cancer_Detection/vgg_pretrained.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, label_dir, save_dir, epoch, mb, num_class, num_workers, use_cuda, conti, lr, save, name, train_prop)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mloss_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMelaData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mval_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/skin_cancer/Skin_Cancer_Detection/vgg_pretrained.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, label_csv, transform)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mdx_to_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'nv'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bkl'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'akiec'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bcc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vasc'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdx_to_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[0;32m--> 433\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    434\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "loss_train, acc_train, val_data = train(data_dir = data_d, label_dir = label_dir, save_dir = save_dir, epoch = epoch, mb = mb, num_class = num_class, num_workers = num_workers, use_cuda = cuda, conti = conti, lr = lr, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg_preloaded(\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Dropout(p=0.5)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace)\n",
       "      (5): Dropout(p=0.5)\n",
       "      (6): Linear(in_features=4096, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_dir, val_data, label_dir, batch_size, num_workers = 1, use_cuda = False):\n",
    "    model = vgg_preloaded(7, use_cuda=use_cuda)\n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "    model = model.cuda() if use_cuda else model\n",
    "\n",
    "    #dataset = MelaData(data_dir = data_dir, label_csv = label_dir)\n",
    "    dataloader = DataLoader(val_data, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "    model.eval()\n",
    "    predictions = [] #Store predictions in here\n",
    "    class_list = [] #store ground truth here\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    count = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader)\n",
    "    pbar.set_description(\"[Epoch {}]\".format('Validation'))\n",
    "    for inputs,classes in pbar:\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            classes = classes.cuda()\n",
    "        else:\n",
    "            inputs = inputs\n",
    "            classes = classes\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs,classes) \n",
    "        _,preds = torch.max(outputs.data, 1)\n",
    "        running_loss += loss.cpu().data.item()\n",
    "        running_corrects += preds.eq(classes.view_as(preds)).sum()\n",
    "        predictions += list(preds.cpu().data.numpy())\n",
    "        if use_cuda:\n",
    "            class_save = classes.cpu().data.numpy()\n",
    "        else:\n",
    "            class_save = classes.data.numpy()\n",
    "        class_list.append(class_save)\n",
    "        count +=1\n",
    "\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / len(val_data), running_corrects.data.item() / len(val_data)))\n",
    "    return({'loss': running_loss / len(val_data), 'acc': running_corrects.data.item() / len(val_data), 'predictions': predictions, 'classes': class_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch Validation]: 100%|██████████| 251/251 [01:01<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6949 Acc: 0.7636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "model_dir = '/home/paperspace/projects/skin_cancer/data/res_model/model.pt'\n",
    "val_data = val_data\n",
    "label_dir = None\n",
    "batch_size = 1\n",
    "use_cuda = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "res = test_model(model_dir = model_dir, val_data = val_data, label_dir = label_dir, batch_size = 12, use_cuda = use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'predictions', 'classes'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2544, 1: 35, 2: 149, 3: 5, 4: 53, 5: 189, 6: 29})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(res['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2, 0, 0, 0, 2, 5, 0, 0, 2, 0, 5, 5]),\n",
       " array([5, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 6, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0]),\n",
       " array([0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 4, 4]),\n",
       " array([0, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 5, 0, 2, 0, 6]),\n",
       " array([0, 0, 4, 0, 0, 5, 4, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0]),\n",
       " array([0, 0, 3, 1, 0, 0, 0, 0, 0, 5, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 6, 0, 2, 1, 0, 0, 0]),\n",
       " array([2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0]),\n",
       " array([0, 0, 0, 0, 5, 0, 5, 2, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 5, 0, 2, 1, 0, 2, 2, 0]),\n",
       " array([0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 6, 0, 0, 0, 0, 0, 5, 0, 0]),\n",
       " array([0, 1, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 2, 5, 0, 0]),\n",
       " array([0, 4, 0, 0, 0, 4, 1, 0, 6, 0, 1, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2]),\n",
       " array([0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2]),\n",
       " array([0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 5, 0, 1, 0, 2, 1, 0, 0]),\n",
       " array([2, 0, 0, 2, 5, 0, 0, 2, 2, 0, 1, 0]),\n",
       " array([0, 0, 0, 1, 2, 0, 2, 4, 5, 0, 0, 5]),\n",
       " array([1, 5, 0, 4, 4, 0, 0, 0, 0, 4, 5, 1]),\n",
       " array([2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0]),\n",
       " array([2, 5, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2]),\n",
       " array([0, 2, 1, 0, 0, 5, 0, 0, 5, 0, 0, 0]),\n",
       " array([2, 1, 2, 0, 1, 0, 0, 5, 0, 0, 3, 0]),\n",
       " array([0, 0, 0, 4, 0, 6, 0, 0, 0, 0, 2, 0]),\n",
       " array([0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 5]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 2]),\n",
       " array([0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0]),\n",
       " array([0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 5, 1, 0, 2, 5, 1, 0, 5, 0, 3, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 4, 0]),\n",
       " array([0, 0, 1, 0, 4, 1, 0, 0, 0, 1, 4, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 2]),\n",
       " array([2, 0, 0, 1, 6, 0, 0, 2, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0]),\n",
       " array([0, 0, 4, 0, 4, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 2, 0, 0, 2, 0, 1, 0, 0, 0, 0, 5]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]),\n",
       " array([1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5]),\n",
       " array([0, 2, 1, 0, 5, 1, 0, 0, 3, 0, 2, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 2, 5, 0, 1, 0, 0, 0, 0, 0, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]),\n",
       " array([3, 0, 5, 2, 0, 2, 0, 2, 6, 2, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]),\n",
       " array([0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0]),\n",
       " array([2, 5, 0, 1, 0, 5, 0, 0, 0, 2, 1, 5]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0]),\n",
       " array([2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 6, 0, 0, 0, 0, 1, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0, 2]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0]),\n",
       " array([0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 5, 2]),\n",
       " array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 5, 0, 5, 0, 3, 0, 5, 1, 5, 0, 0]),\n",
       " array([0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0]),\n",
       " array([2, 0, 0, 0, 5, 1, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 4, 0, 2, 5, 0, 0, 0, 5]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 4, 5, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 5, 0, 0, 2, 0, 2, 2]),\n",
       " array([0, 0, 1, 3, 0, 0, 5, 0, 0, 0, 0, 5]),\n",
       " array([0, 2, 0, 0, 5, 0, 4, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([2, 0, 0, 0, 6, 0, 0, 0, 0, 1, 2, 0]),\n",
       " array([0, 0, 1, 1, 0, 0, 4, 2, 0, 5, 0, 2]),\n",
       " array([2, 0, 0, 0, 0, 5, 5, 0, 5, 0, 4, 0]),\n",
       " array([4, 0, 0, 0, 2, 0, 5, 0, 0, 0, 2, 0]),\n",
       " array([1, 0, 0, 5, 1, 4, 2, 0, 1, 2, 0, 0]),\n",
       " array([2, 0, 1, 0, 0, 4, 0, 0, 2, 5, 0, 0]),\n",
       " array([0, 0, 4, 0, 0, 0, 0, 1, 0, 5, 2, 4]),\n",
       " array([5, 4, 1, 0, 0, 0, 2, 4, 0, 0, 0, 4]),\n",
       " array([5, 0, 0, 2, 0, 5, 0, 0, 0, 5, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0]),\n",
       " array([0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 1, 0]),\n",
       " array([5, 2, 0, 0, 5, 0, 0, 2, 1, 0, 0, 0]),\n",
       " array([2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 4, 0, 6, 2, 0]),\n",
       " array([0, 0, 0, 0, 0, 6, 2, 2, 0, 2, 2, 0]),\n",
       " array([0, 0, 0, 0, 2, 0, 0, 1, 0, 4, 2, 0]),\n",
       " array([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]),\n",
       " array([2, 0, 2, 0, 5, 0, 0, 5, 4, 0, 5, 0]),\n",
       " array([6, 1, 1, 1, 0, 0, 0, 4, 0, 0, 0, 4]),\n",
       " array([0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 5, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 5]),\n",
       " array([1, 0, 1, 0, 4, 0, 4, 0, 0, 1, 6, 0]),\n",
       " array([4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 1, 1]),\n",
       " array([0, 0, 0, 1, 2, 2, 0, 1, 0, 4, 2, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 2, 4, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2]),\n",
       " array([0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0]),\n",
       " array([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0]),\n",
       " array([2, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0]),\n",
       " array([6, 0, 0, 0, 0, 0, 2, 0, 0, 5, 0, 0]),\n",
       " array([0, 0, 1, 0, 1, 0, 5, 0, 5, 0, 0, 4]),\n",
       " array([5, 0, 0, 5, 4, 0, 0, 5, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 2, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 4, 0, 0, 0, 0, 0, 2, 1, 6, 2]),\n",
       " array([1, 1, 0, 0, 2, 0, 0, 0, 6, 1, 0, 0]),\n",
       " array([2, 4, 4, 2, 0, 0, 0, 2, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 1, 2, 0, 0, 5, 0, 2, 0, 0]),\n",
       " array([0, 0, 6, 2, 0, 0, 2, 4, 0, 0, 0, 2]),\n",
       " array([0, 0, 0, 0, 1, 2, 5, 2, 1, 0, 2, 0])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[arr for arr in res['classes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1045, 1: 129, 2: 148, 3: 11, 4: 60, 5: 89, 6: 18})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([item for sublist in res['classes'] for item in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPARTITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_pretrained import vgg_preloaded, MelaData, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, utils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_images_part_1/'\n",
    "label_dir = '/home/paperspace/projects/skin_cancer/data/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n",
    "save_dir = '/home/paperspace/projects/skin_cancer/data/res_model/'\n",
    "epoch = 2\n",
    "mb = 24\n",
    "num_class = 7\n",
    "num_workers = 1\n",
    "cuda = True\n",
    "conti = False\n",
    "save = True\n",
    "name = 'test_model'\n",
    "lr = 1e-3\n",
    "stage = 'transfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/293 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch 1]:   0%|          | 0/293 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch 1]:   0%|          | 1/293 [00:00<04:11,  1.16it/s]\u001b[A\n",
      "[Epoch 1]:   1%|          | 2/293 [00:01<03:20,  1.45it/s]\u001b[A\n",
      "[Epoch 1]:   1%|          | 3/293 [00:01<03:02,  1.59it/s]\u001b[A\n",
      "[Epoch 1]:   1%|▏         | 4/293 [00:02<02:53,  1.67it/s]\u001b[A\n",
      "[Epoch 1]:   2%|▏         | 5/293 [00:02<02:47,  1.72it/s]\u001b[A\n",
      "[Epoch 1]:   2%|▏         | 6/293 [00:03<02:43,  1.76it/s]\u001b[A\n",
      "[Epoch 1]:   2%|▏         | 7/293 [00:03<02:39,  1.79it/s]\u001b[A\n",
      "[Epoch 1]:   3%|▎         | 8/293 [00:04<02:37,  1.81it/s]\u001b[A\n",
      "[Epoch 1]:   3%|▎         | 9/293 [00:04<02:35,  1.83it/s]\u001b[A\n",
      "[Epoch 1]:   3%|▎         | 10/293 [00:05<02:33,  1.85it/s]\u001b[A\n",
      "[Epoch 1]:   4%|▍         | 11/293 [00:05<02:31,  1.86it/s]\u001b[A\n",
      "[Epoch 1]:   4%|▍         | 12/293 [00:06<02:30,  1.87it/s]\u001b[A\n",
      "[Epoch 1]:   4%|▍         | 13/293 [00:06<02:29,  1.88it/s]\u001b[A\n",
      "[Epoch 1]:   5%|▍         | 14/293 [00:07<02:27,  1.89it/s]\u001b[A\n",
      "[Epoch 1]:   5%|▌         | 15/293 [00:07<02:26,  1.89it/s]\u001b[A\n",
      "[Epoch 1]:   5%|▌         | 16/293 [00:08<02:26,  1.90it/s]\u001b[A\n",
      "[Epoch 1]:   6%|▌         | 17/293 [00:08<02:25,  1.90it/s]\u001b[A\n",
      "[Epoch 1]:   6%|▌         | 18/293 [00:09<02:24,  1.91it/s]\u001b[A\n",
      "[Epoch 1]:   6%|▋         | 19/293 [00:09<02:23,  1.91it/s]\u001b[A\n",
      "[Epoch 1]:   7%|▋         | 20/293 [00:10<02:22,  1.92it/s]\u001b[A\n",
      "[Epoch 1]:   7%|▋         | 21/293 [00:10<02:21,  1.92it/s]\u001b[A\n",
      "[Epoch 1]:   8%|▊         | 22/293 [00:11<02:21,  1.92it/s]\u001b[A\n",
      "[Epoch 1]:   8%|▊         | 23/293 [00:11<02:20,  1.92it/s]\u001b[A\n",
      "[Epoch 1]:   8%|▊         | 24/293 [00:12<02:19,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:   9%|▊         | 25/293 [00:12<02:18,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:   9%|▉         | 26/293 [00:13<02:18,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:   9%|▉         | 27/293 [00:13<02:17,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:  10%|▉         | 28/293 [00:14<02:16,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  10%|▉         | 29/293 [00:14<02:16,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  10%|█         | 30/293 [00:15<02:15,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  11%|█         | 31/293 [00:15<02:15,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  11%|█         | 32/293 [00:16<02:14,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  11%|█▏        | 33/293 [00:16<02:13,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  12%|█▏        | 34/293 [00:17<02:13,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  12%|█▏        | 35/293 [00:18<02:12,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  12%|█▏        | 36/293 [00:18<02:12,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:  13%|█▎        | 37/293 [00:19<02:11,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  13%|█▎        | 38/293 [00:19<02:10,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  13%|█▎        | 39/293 [00:20<02:10,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  14%|█▎        | 40/293 [00:20<02:09,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  14%|█▍        | 41/293 [00:21<02:09,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  14%|█▍        | 42/293 [00:21<02:08,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  15%|█▍        | 43/293 [00:22<02:08,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  15%|█▌        | 44/293 [00:22<02:07,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  15%|█▌        | 45/293 [00:23<02:07,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  16%|█▌        | 46/293 [00:23<02:06,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  16%|█▌        | 47/293 [00:24<02:05,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  16%|█▋        | 48/293 [00:24<02:05,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  17%|█▋        | 49/293 [00:25<02:04,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  17%|█▋        | 50/293 [00:25<02:04,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  17%|█▋        | 51/293 [00:26<02:03,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  18%|█▊        | 52/293 [00:26<02:03,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  18%|█▊        | 53/293 [00:27<02:02,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  18%|█▊        | 54/293 [00:27<02:02,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  19%|█▉        | 55/293 [00:28<02:01,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  19%|█▉        | 56/293 [00:28<02:01,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  19%|█▉        | 57/293 [00:29<02:00,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  20%|█▉        | 58/293 [00:29<02:00,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  20%|██        | 59/293 [00:30<01:59,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  20%|██        | 60/293 [00:30<01:58,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  21%|██        | 61/293 [00:31<01:58,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  21%|██        | 62/293 [00:31<01:57,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  22%|██▏       | 63/293 [00:32<01:57,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  22%|██▏       | 64/293 [00:32<01:56,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  22%|██▏       | 65/293 [00:33<01:56,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  23%|██▎       | 66/293 [00:33<01:55,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  23%|██▎       | 67/293 [00:34<01:55,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  23%|██▎       | 68/293 [00:34<01:54,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  24%|██▎       | 69/293 [00:35<01:54,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  24%|██▍       | 70/293 [00:35<01:53,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  24%|██▍       | 71/293 [00:36<01:53,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  25%|██▍       | 72/293 [00:36<01:52,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  25%|██▍       | 73/293 [00:37<01:52,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  25%|██▌       | 74/293 [00:37<01:51,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  26%|██▌       | 75/293 [00:38<01:51,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  26%|██▌       | 76/293 [00:38<01:50,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  26%|██▋       | 77/293 [00:39<01:49,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  27%|██▋       | 78/293 [00:39<01:49,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  27%|██▋       | 79/293 [00:40<01:48,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  27%|██▋       | 80/293 [00:40<01:48,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  28%|██▊       | 81/293 [00:41<01:47,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  28%|██▊       | 82/293 [00:41<01:47,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  28%|██▊       | 83/293 [00:42<01:46,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  29%|██▊       | 84/293 [00:42<01:46,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  29%|██▉       | 85/293 [00:43<01:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  29%|██▉       | 86/293 [00:43<01:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  30%|██▉       | 87/293 [00:44<01:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  30%|███       | 88/293 [00:44<01:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  30%|███       | 89/293 [00:45<01:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  31%|███       | 90/293 [00:45<01:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  31%|███       | 91/293 [00:46<01:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  31%|███▏      | 92/293 [00:46<01:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  32%|███▏      | 93/293 [00:47<01:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  32%|███▏      | 94/293 [00:47<01:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  32%|███▏      | 95/293 [00:48<01:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  33%|███▎      | 96/293 [00:48<01:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  33%|███▎      | 97/293 [00:49<01:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  33%|███▎      | 98/293 [00:49<01:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  34%|███▍      | 99/293 [00:50<01:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  34%|███▍      | 100/293 [00:50<01:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  34%|███▍      | 101/293 [00:51<01:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  35%|███▍      | 102/293 [00:51<01:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  35%|███▌      | 103/293 [00:52<01:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  35%|███▌      | 104/293 [00:52<01:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  36%|███▌      | 105/293 [00:53<01:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  36%|███▌      | 106/293 [00:53<01:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  37%|███▋      | 107/293 [00:54<01:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  37%|███▋      | 108/293 [00:54<01:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  37%|███▋      | 109/293 [00:55<01:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  38%|███▊      | 110/293 [00:55<01:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  38%|███▊      | 111/293 [00:56<01:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  38%|███▊      | 112/293 [00:56<01:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  39%|███▊      | 113/293 [00:57<01:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  39%|███▉      | 114/293 [00:57<01:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  39%|███▉      | 115/293 [00:58<01:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  40%|███▉      | 116/293 [00:58<01:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  40%|███▉      | 117/293 [00:59<01:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  40%|████      | 118/293 [00:59<01:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  41%|████      | 119/293 [01:00<01:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  41%|████      | 120/293 [01:00<01:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  41%|████▏     | 121/293 [01:01<01:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  42%|████▏     | 122/293 [01:01<01:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  42%|████▏     | 123/293 [01:02<01:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  42%|████▏     | 124/293 [01:02<01:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  43%|████▎     | 125/293 [01:03<01:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  43%|████▎     | 126/293 [01:03<01:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  43%|████▎     | 127/293 [01:04<01:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  44%|████▎     | 128/293 [01:04<01:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  44%|████▍     | 129/293 [01:05<01:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  44%|████▍     | 130/293 [01:05<01:22,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  45%|████▍     | 131/293 [01:06<01:22,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  45%|████▌     | 132/293 [01:06<01:21,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  45%|████▌     | 133/293 [01:07<01:21,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  46%|████▌     | 134/293 [01:08<01:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  46%|████▌     | 135/293 [01:08<01:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  46%|████▋     | 136/293 [01:09<01:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  47%|████▋     | 137/293 [01:09<01:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  47%|████▋     | 138/293 [01:10<01:18,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  47%|████▋     | 139/293 [01:10<01:18,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  48%|████▊     | 140/293 [01:11<01:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  48%|████▊     | 141/293 [01:11<01:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  48%|████▊     | 142/293 [01:12<01:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  49%|████▉     | 143/293 [01:12<01:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  49%|████▉     | 144/293 [01:13<01:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  49%|████▉     | 145/293 [01:13<01:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  50%|████▉     | 146/293 [01:14<01:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  50%|█████     | 147/293 [01:14<01:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  51%|█████     | 148/293 [01:15<01:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  51%|█████     | 149/293 [01:15<01:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  51%|█████     | 150/293 [01:16<01:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  52%|█████▏    | 151/293 [01:16<01:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  52%|█████▏    | 152/293 [01:17<01:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  52%|█████▏    | 153/293 [01:17<01:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  53%|█████▎    | 154/293 [01:18<01:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  53%|█████▎    | 155/293 [01:18<01:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  53%|█████▎    | 156/293 [01:19<01:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  54%|█████▎    | 157/293 [01:19<01:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  54%|█████▍    | 158/293 [01:20<01:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  54%|█████▍    | 159/293 [01:20<01:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  55%|█████▍    | 160/293 [01:21<01:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  55%|█████▍    | 161/293 [01:21<01:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  55%|█████▌    | 162/293 [01:22<01:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  56%|█████▌    | 163/293 [01:22<01:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  56%|█████▌    | 164/293 [01:23<01:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  56%|█████▋    | 165/293 [01:23<01:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  57%|█████▋    | 166/293 [01:24<01:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  57%|█████▋    | 167/293 [01:24<01:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  57%|█████▋    | 168/293 [01:25<01:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  58%|█████▊    | 169/293 [01:25<01:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  58%|█████▊    | 170/293 [01:26<01:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  58%|█████▊    | 171/293 [01:26<01:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  59%|█████▊    | 172/293 [01:27<01:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  59%|█████▉    | 173/293 [01:27<01:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  59%|█████▉    | 174/293 [01:28<01:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  60%|█████▉    | 175/293 [01:28<00:59,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  60%|██████    | 176/293 [01:29<00:59,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  60%|██████    | 177/293 [01:29<00:58,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  61%|██████    | 178/293 [01:30<00:58,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  61%|██████    | 179/293 [01:30<00:57,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  61%|██████▏   | 180/293 [01:31<00:57,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  62%|██████▏   | 181/293 [01:31<00:56,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  62%|██████▏   | 182/293 [01:32<00:56,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  62%|██████▏   | 183/293 [01:32<00:55,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  63%|██████▎   | 184/293 [01:33<00:55,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  63%|██████▎   | 185/293 [01:33<00:54,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  63%|██████▎   | 186/293 [01:34<00:54,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  64%|██████▍   | 187/293 [01:34<00:53,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  64%|██████▍   | 188/293 [01:35<00:53,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  65%|██████▍   | 189/293 [01:35<00:52,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  65%|██████▍   | 190/293 [01:36<00:52,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  65%|██████▌   | 191/293 [01:36<00:51,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  66%|██████▌   | 192/293 [01:37<00:51,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  66%|██████▌   | 193/293 [01:37<00:50,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  66%|██████▌   | 194/293 [01:38<00:50,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  67%|██████▋   | 195/293 [01:38<00:49,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  67%|██████▋   | 196/293 [01:39<00:49,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  67%|██████▋   | 197/293 [01:39<00:48,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  68%|██████▊   | 198/293 [01:40<00:48,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  68%|██████▊   | 199/293 [01:40<00:47,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  68%|██████▊   | 200/293 [01:41<00:47,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  69%|██████▊   | 201/293 [01:41<00:46,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  69%|██████▉   | 202/293 [01:42<00:46,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  69%|██████▉   | 203/293 [01:42<00:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  70%|██████▉   | 204/293 [01:43<00:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  70%|██████▉   | 205/293 [01:43<00:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  70%|███████   | 206/293 [01:44<00:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  71%|███████   | 207/293 [01:44<00:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  71%|███████   | 208/293 [01:45<00:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  71%|███████▏  | 209/293 [01:45<00:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  72%|███████▏  | 210/293 [01:46<00:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  72%|███████▏  | 211/293 [01:46<00:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  72%|███████▏  | 212/293 [01:47<00:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  73%|███████▎  | 213/293 [01:47<00:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  73%|███████▎  | 214/293 [01:48<00:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  73%|███████▎  | 215/293 [01:49<00:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  74%|███████▎  | 216/293 [01:49<00:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  74%|███████▍  | 217/293 [01:50<00:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  74%|███████▍  | 218/293 [01:50<00:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  75%|███████▍  | 219/293 [01:51<00:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  75%|███████▌  | 220/293 [01:51<00:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  75%|███████▌  | 221/293 [01:52<00:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  76%|███████▌  | 222/293 [01:52<00:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  76%|███████▌  | 223/293 [01:53<00:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  76%|███████▋  | 224/293 [01:53<00:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  77%|███████▋  | 225/293 [01:54<00:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  77%|███████▋  | 226/293 [01:54<00:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  77%|███████▋  | 227/293 [01:55<00:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  78%|███████▊  | 228/293 [01:55<00:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  78%|███████▊  | 229/293 [01:56<00:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  78%|███████▊  | 230/293 [01:56<00:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  79%|███████▉  | 231/293 [01:57<00:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  79%|███████▉  | 232/293 [01:57<00:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  80%|███████▉  | 233/293 [01:58<00:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  80%|███████▉  | 234/293 [01:58<00:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  80%|████████  | 235/293 [01:59<00:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  81%|████████  | 236/293 [01:59<00:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  81%|████████  | 237/293 [02:00<00:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  81%|████████  | 238/293 [02:00<00:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  82%|████████▏ | 239/293 [02:01<00:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  82%|████████▏ | 240/293 [02:01<00:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  82%|████████▏ | 241/293 [02:02<00:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  83%|████████▎ | 242/293 [02:02<00:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  83%|████████▎ | 243/293 [02:03<00:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  83%|████████▎ | 244/293 [02:03<00:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  84%|████████▎ | 245/293 [02:04<00:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  84%|████████▍ | 246/293 [02:04<00:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  84%|████████▍ | 247/293 [02:05<00:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  85%|████████▍ | 248/293 [02:05<00:22,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  85%|████████▍ | 249/293 [02:06<00:22,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  85%|████████▌ | 250/293 [02:06<00:21,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  86%|████████▌ | 251/293 [02:07<00:21,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  86%|████████▌ | 252/293 [02:07<00:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  86%|████████▋ | 253/293 [02:08<00:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  87%|████████▋ | 254/293 [02:08<00:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  87%|████████▋ | 255/293 [02:09<00:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  87%|████████▋ | 256/293 [02:09<00:18,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]:  88%|████████▊ | 257/293 [02:10<00:18,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  88%|████████▊ | 258/293 [02:10<00:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  88%|████████▊ | 259/293 [02:11<00:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  89%|████████▊ | 260/293 [02:12<00:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  89%|████████▉ | 261/293 [02:12<00:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  89%|████████▉ | 262/293 [02:13<00:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  90%|████████▉ | 263/293 [02:13<00:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  90%|█████████ | 264/293 [02:14<00:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  90%|█████████ | 265/293 [02:14<00:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  91%|█████████ | 266/293 [02:15<00:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  91%|█████████ | 267/293 [02:15<00:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  91%|█████████▏| 268/293 [02:16<00:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  92%|█████████▏| 269/293 [02:16<00:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  92%|█████████▏| 270/293 [02:17<00:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  92%|█████████▏| 271/293 [02:17<00:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  93%|█████████▎| 272/293 [02:18<00:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  93%|█████████▎| 273/293 [02:18<00:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  94%|█████████▎| 274/293 [02:19<00:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  94%|█████████▍| 275/293 [02:19<00:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  94%|█████████▍| 276/293 [02:20<00:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  95%|█████████▍| 277/293 [02:20<00:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  95%|█████████▍| 278/293 [02:21<00:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  95%|█████████▌| 279/293 [02:21<00:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  96%|█████████▌| 280/293 [02:22<00:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  96%|█████████▌| 281/293 [02:22<00:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  96%|█████████▌| 282/293 [02:23<00:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  97%|█████████▋| 283/293 [02:23<00:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  97%|█████████▋| 284/293 [02:24<00:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  97%|█████████▋| 285/293 [02:24<00:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  98%|█████████▊| 286/293 [02:25<00:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  98%|█████████▊| 287/293 [02:25<00:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  98%|█████████▊| 288/293 [02:26<00:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  99%|█████████▊| 289/293 [02:26<00:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  99%|█████████▉| 290/293 [02:27<00:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  99%|█████████▉| 291/293 [02:27<00:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]: 100%|█████████▉| 292/293 [02:28<00:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]: 100%|██████████| 293/293 [02:28<00:00,  1.97it/s]\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/293 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch 2]:   0%|          | 0/293 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.1119 Acc: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2]:   0%|          | 1/293 [00:00<03:16,  1.49it/s]\u001b[A\n",
      "[Epoch 2]:   1%|          | 2/293 [00:01<02:53,  1.68it/s]\u001b[A\n",
      "[Epoch 2]:   1%|          | 3/293 [00:01<02:45,  1.75it/s]\u001b[A\n",
      "[Epoch 2]:   1%|▏         | 4/293 [00:02<02:41,  1.79it/s]\u001b[A\n",
      "[Epoch 2]:   2%|▏         | 5/293 [00:02<02:38,  1.82it/s]\u001b[A\n",
      "[Epoch 2]:   2%|▏         | 6/293 [00:03<02:36,  1.84it/s]\u001b[A\n",
      "[Epoch 2]:   2%|▏         | 7/293 [00:03<02:34,  1.85it/s]\u001b[A\n",
      "[Epoch 2]:   3%|▎         | 8/293 [00:04<02:32,  1.86it/s]\u001b[A\n",
      "[Epoch 2]:   3%|▎         | 9/293 [00:04<02:31,  1.87it/s]\u001b[A\n",
      "[Epoch 2]:   3%|▎         | 10/293 [00:05<02:30,  1.88it/s]\u001b[A\n",
      "[Epoch 2]:   4%|▍         | 11/293 [00:05<02:29,  1.89it/s]\u001b[A\n",
      "[Epoch 2]:   4%|▍         | 12/293 [00:06<02:28,  1.89it/s]\u001b[A\n",
      "[Epoch 2]:   4%|▍         | 13/293 [00:06<02:27,  1.90it/s]\u001b[A\n",
      "[Epoch 2]:   5%|▍         | 14/293 [00:07<02:26,  1.90it/s]\u001b[A\n",
      "[Epoch 2]:   5%|▌         | 15/293 [00:07<02:25,  1.91it/s]\u001b[A\n",
      "[Epoch 2]:   5%|▌         | 16/293 [00:08<02:25,  1.91it/s]\u001b[A\n",
      "[Epoch 2]:   6%|▌         | 17/293 [00:08<02:24,  1.91it/s]\u001b[A\n",
      "[Epoch 2]:   6%|▌         | 18/293 [00:09<02:23,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   6%|▋         | 19/293 [00:09<02:22,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   7%|▋         | 20/293 [00:10<02:22,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   7%|▋         | 21/293 [00:10<02:21,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   8%|▊         | 22/293 [00:11<02:21,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   8%|▊         | 23/293 [00:11<02:20,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   8%|▊         | 24/293 [00:12<02:20,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   9%|▊         | 25/293 [00:13<02:19,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   9%|▉         | 26/293 [00:13<02:18,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:   9%|▉         | 27/293 [00:14<02:18,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:  10%|▉         | 28/293 [00:14<02:17,  1.92it/s]\u001b[A\n",
      "[Epoch 2]:  10%|▉         | 29/293 [00:15<02:17,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  10%|█         | 30/293 [00:15<02:16,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  11%|█         | 31/293 [00:16<02:15,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  11%|█         | 32/293 [00:16<02:15,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  11%|█▏        | 33/293 [00:17<02:14,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  12%|█▏        | 34/293 [00:17<02:14,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  12%|█▏        | 35/293 [00:18<02:13,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  12%|█▏        | 36/293 [00:18<02:13,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  13%|█▎        | 37/293 [00:19<02:12,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  13%|█▎        | 38/293 [00:19<02:12,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  13%|█▎        | 39/293 [00:20<02:11,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  14%|█▎        | 40/293 [00:20<02:11,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  14%|█▍        | 41/293 [00:21<02:10,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  14%|█▍        | 42/293 [00:21<02:10,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  15%|█▍        | 43/293 [00:22<02:09,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  15%|█▌        | 44/293 [00:22<02:08,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  15%|█▌        | 45/293 [00:23<02:08,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  16%|█▌        | 46/293 [00:23<02:07,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  16%|█▌        | 47/293 [00:24<02:07,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  16%|█▋        | 48/293 [00:24<02:06,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  17%|█▋        | 49/293 [00:25<02:06,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  17%|█▋        | 50/293 [00:25<02:05,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  17%|█▋        | 51/293 [00:26<02:05,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  18%|█▊        | 52/293 [00:26<02:04,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  18%|█▊        | 53/293 [00:27<02:03,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  18%|█▊        | 54/293 [00:27<02:03,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  19%|█▉        | 55/293 [00:28<02:02,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  19%|█▉        | 56/293 [00:28<02:02,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  19%|█▉        | 57/293 [00:29<02:01,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  20%|█▉        | 58/293 [00:29<02:01,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  20%|██        | 59/293 [00:30<02:00,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  20%|██        | 60/293 [00:31<02:00,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  21%|██        | 61/293 [00:31<01:59,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  21%|██        | 62/293 [00:32<01:59,  1.93it/s]\u001b[A\n",
      "[Epoch 2]:  22%|██▏       | 63/293 [00:32<01:58,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  22%|██▏       | 64/293 [00:33<01:58,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  22%|██▏       | 65/293 [00:33<01:57,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  23%|██▎       | 66/293 [00:34<01:57,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  23%|██▎       | 67/293 [00:34<01:56,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  23%|██▎       | 68/293 [00:35<01:56,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  24%|██▎       | 69/293 [00:35<01:55,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  24%|██▍       | 70/293 [00:36<01:55,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  24%|██▍       | 71/293 [00:36<01:54,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  25%|██▍       | 72/293 [00:37<01:53,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  25%|██▍       | 73/293 [00:37<01:53,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  25%|██▌       | 74/293 [00:38<01:52,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  26%|██▌       | 75/293 [00:38<01:52,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  26%|██▌       | 76/293 [00:39<01:51,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  26%|██▋       | 77/293 [00:39<01:51,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  27%|██▋       | 78/293 [00:40<01:50,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  27%|██▋       | 79/293 [00:40<01:50,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  27%|██▋       | 80/293 [00:41<01:49,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  28%|██▊       | 81/293 [00:41<01:49,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  28%|██▊       | 82/293 [00:42<01:48,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  28%|██▊       | 83/293 [00:42<01:48,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  29%|██▊       | 84/293 [00:43<01:47,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  29%|██▉       | 85/293 [00:43<01:47,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  29%|██▉       | 86/293 [00:44<01:46,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  30%|██▉       | 87/293 [00:44<01:46,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  30%|███       | 88/293 [00:45<01:45,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  30%|███       | 89/293 [00:45<01:45,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  31%|███       | 90/293 [00:46<01:44,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  31%|███       | 91/293 [00:46<01:44,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  31%|███▏      | 92/293 [00:47<01:43,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  32%|███▏      | 93/293 [00:47<01:43,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  32%|███▏      | 94/293 [00:48<01:42,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  32%|███▏      | 95/293 [00:48<01:41,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  33%|███▎      | 96/293 [00:49<01:41,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  33%|███▎      | 97/293 [00:49<01:40,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  33%|███▎      | 98/293 [00:50<01:40,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  34%|███▍      | 99/293 [00:50<01:39,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  34%|███▍      | 100/293 [00:51<01:39,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  34%|███▍      | 101/293 [00:52<01:38,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  35%|███▍      | 102/293 [00:52<01:38,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  35%|███▌      | 103/293 [00:53<01:37,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  35%|███▌      | 104/293 [00:53<01:37,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  36%|███▌      | 105/293 [00:54<01:36,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  36%|███▌      | 106/293 [00:54<01:36,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  37%|███▋      | 107/293 [00:55<01:35,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  37%|███▋      | 108/293 [00:55<01:35,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  37%|███▋      | 109/293 [00:56<01:34,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  38%|███▊      | 110/293 [00:56<01:34,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  38%|███▊      | 111/293 [00:57<01:33,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  38%|███▊      | 112/293 [00:57<01:33,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  39%|███▊      | 113/293 [00:58<01:32,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  39%|███▉      | 114/293 [00:58<01:32,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  39%|███▉      | 115/293 [00:59<01:31,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  40%|███▉      | 116/293 [00:59<01:31,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  40%|███▉      | 117/293 [01:00<01:30,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  40%|████      | 118/293 [01:00<01:30,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  41%|████      | 119/293 [01:01<01:29,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  41%|████      | 120/293 [01:01<01:29,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  41%|████▏     | 121/293 [01:02<01:28,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  42%|████▏     | 122/293 [01:02<01:28,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  42%|████▏     | 123/293 [01:03<01:27,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  42%|████▏     | 124/293 [01:03<01:26,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  43%|████▎     | 125/293 [01:04<01:26,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  43%|████▎     | 126/293 [01:04<01:25,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  43%|████▎     | 127/293 [01:05<01:25,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  44%|████▎     | 128/293 [01:05<01:24,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  44%|████▍     | 129/293 [01:06<01:24,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  44%|████▍     | 130/293 [01:06<01:23,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  45%|████▍     | 131/293 [01:07<01:23,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  45%|████▌     | 132/293 [01:07<01:22,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  45%|████▌     | 133/293 [01:08<01:22,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  46%|████▌     | 134/293 [01:08<01:21,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  46%|████▌     | 135/293 [01:09<01:21,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  46%|████▋     | 136/293 [01:09<01:20,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  47%|████▋     | 137/293 [01:10<01:20,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  47%|████▋     | 138/293 [01:10<01:19,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  47%|████▋     | 139/293 [01:11<01:19,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  48%|████▊     | 140/293 [01:12<01:18,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  48%|████▊     | 141/293 [01:12<01:18,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  48%|████▊     | 142/293 [01:13<01:17,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  49%|████▉     | 143/293 [01:13<01:17,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  49%|████▉     | 144/293 [01:14<01:16,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  49%|████▉     | 145/293 [01:14<01:16,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  50%|████▉     | 146/293 [01:15<01:15,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  50%|█████     | 147/293 [01:15<01:15,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  51%|█████     | 148/293 [01:16<01:14,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  51%|█████     | 149/293 [01:16<01:14,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  51%|█████     | 150/293 [01:17<01:13,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  52%|█████▏    | 151/293 [01:17<01:13,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  52%|█████▏    | 152/293 [01:18<01:12,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  52%|█████▏    | 153/293 [01:18<01:11,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  53%|█████▎    | 154/293 [01:19<01:11,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  53%|█████▎    | 155/293 [01:19<01:10,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  53%|█████▎    | 156/293 [01:20<01:10,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  54%|█████▎    | 157/293 [01:20<01:09,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  54%|█████▍    | 158/293 [01:21<01:09,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  54%|█████▍    | 159/293 [01:21<01:08,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  55%|█████▍    | 160/293 [01:22<01:08,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  55%|█████▍    | 161/293 [01:22<01:07,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  55%|█████▌    | 162/293 [01:23<01:07,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  56%|█████▌    | 163/293 [01:23<01:06,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  56%|█████▌    | 164/293 [01:24<01:06,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  56%|█████▋    | 165/293 [01:24<01:05,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  57%|█████▋    | 166/293 [01:25<01:05,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  57%|█████▋    | 167/293 [01:25<01:04,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  57%|█████▋    | 168/293 [01:26<01:04,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  58%|█████▊    | 169/293 [01:26<01:03,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  58%|█████▊    | 170/293 [01:27<01:03,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  58%|█████▊    | 171/293 [01:27<01:02,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  59%|█████▊    | 172/293 [01:28<01:02,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  59%|█████▉    | 173/293 [01:28<01:01,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  59%|█████▉    | 174/293 [01:29<01:01,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  60%|█████▉    | 175/293 [01:29<01:00,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  60%|██████    | 176/293 [01:30<01:00,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  60%|██████    | 177/293 [01:30<00:59,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  61%|██████    | 178/293 [01:31<00:59,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  61%|██████    | 179/293 [01:31<00:58,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  61%|██████▏   | 180/293 [01:32<00:58,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  62%|██████▏   | 181/293 [01:32<00:57,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  62%|██████▏   | 182/293 [01:33<00:57,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  62%|██████▏   | 183/293 [01:34<00:56,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  63%|██████▎   | 184/293 [01:34<00:56,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  63%|██████▎   | 185/293 [01:35<00:55,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  63%|██████▎   | 186/293 [01:35<00:54,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  64%|██████▍   | 187/293 [01:36<00:54,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  64%|██████▍   | 188/293 [01:36<00:53,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  65%|██████▍   | 189/293 [01:37<00:53,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  65%|██████▍   | 190/293 [01:37<00:52,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  65%|██████▌   | 191/293 [01:38<00:52,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  66%|██████▌   | 192/293 [01:38<00:51,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  66%|██████▌   | 193/293 [01:39<00:51,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  66%|██████▌   | 194/293 [01:39<00:50,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  67%|██████▋   | 195/293 [01:40<00:50,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  67%|██████▋   | 196/293 [01:40<00:49,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  67%|██████▋   | 197/293 [01:41<00:49,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  68%|██████▊   | 198/293 [01:41<00:48,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  68%|██████▊   | 199/293 [01:42<00:48,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  68%|██████▊   | 200/293 [01:42<00:47,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  69%|██████▊   | 201/293 [01:43<00:47,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  69%|██████▉   | 202/293 [01:43<00:46,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  69%|██████▉   | 203/293 [01:44<00:46,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  70%|██████▉   | 204/293 [01:44<00:45,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  70%|██████▉   | 205/293 [01:45<00:45,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  70%|███████   | 206/293 [01:45<00:44,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  71%|███████   | 207/293 [01:46<00:44,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  71%|███████   | 208/293 [01:46<00:43,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  71%|███████▏  | 209/293 [01:47<00:43,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  72%|███████▏  | 210/293 [01:47<00:42,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  72%|███████▏  | 211/293 [01:48<00:42,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  72%|███████▏  | 212/293 [01:48<00:41,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  73%|███████▎  | 213/293 [01:49<00:41,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  73%|███████▎  | 214/293 [01:49<00:40,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  73%|███████▎  | 215/293 [01:50<00:40,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  74%|███████▎  | 216/293 [01:50<00:39,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  74%|███████▍  | 217/293 [01:51<00:39,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  74%|███████▍  | 218/293 [01:51<00:38,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  75%|███████▍  | 219/293 [01:52<00:37,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  75%|███████▌  | 220/293 [01:52<00:37,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  75%|███████▌  | 221/293 [01:53<00:36,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  76%|███████▌  | 222/293 [01:53<00:36,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  76%|███████▌  | 223/293 [01:54<00:35,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  76%|███████▋  | 224/293 [01:54<00:35,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  77%|███████▋  | 225/293 [01:55<00:34,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  77%|███████▋  | 226/293 [01:55<00:34,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  77%|███████▋  | 227/293 [01:56<00:33,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  78%|███████▊  | 228/293 [01:56<00:33,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  78%|███████▊  | 229/293 [01:57<00:32,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  78%|███████▊  | 230/293 [01:58<00:32,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  79%|███████▉  | 231/293 [01:58<00:31,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  79%|███████▉  | 232/293 [01:59<00:31,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  80%|███████▉  | 233/293 [01:59<00:30,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  80%|███████▉  | 234/293 [02:00<00:30,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  80%|████████  | 235/293 [02:00<00:29,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  81%|████████  | 236/293 [02:01<00:29,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  81%|████████  | 237/293 [02:01<00:28,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  81%|████████  | 238/293 [02:02<00:28,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  82%|████████▏ | 239/293 [02:02<00:27,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  82%|████████▏ | 240/293 [02:03<00:27,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  82%|████████▏ | 241/293 [02:03<00:26,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  83%|████████▎ | 242/293 [02:04<00:26,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  83%|████████▎ | 243/293 [02:04<00:25,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  83%|████████▎ | 244/293 [02:05<00:25,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  84%|████████▎ | 245/293 [02:05<00:24,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  84%|████████▍ | 246/293 [02:06<00:24,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  84%|████████▍ | 247/293 [02:06<00:23,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  85%|████████▍ | 248/293 [02:07<00:23,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  85%|████████▍ | 249/293 [02:07<00:22,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  85%|████████▌ | 250/293 [02:08<00:22,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  86%|████████▌ | 251/293 [02:08<00:21,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  86%|████████▌ | 252/293 [02:09<00:21,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  86%|████████▋ | 253/293 [02:09<00:20,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  87%|████████▋ | 254/293 [02:10<00:20,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  87%|████████▋ | 255/293 [02:10<00:19,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  87%|████████▋ | 256/293 [02:11<00:18,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  88%|████████▊ | 257/293 [02:11<00:18,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]:  88%|████████▊ | 258/293 [02:12<00:17,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  88%|████████▊ | 259/293 [02:12<00:17,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  89%|████████▊ | 260/293 [02:13<00:16,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  89%|████████▉ | 261/293 [02:14<00:16,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  89%|████████▉ | 262/293 [02:14<00:15,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  90%|████████▉ | 263/293 [02:15<00:15,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  90%|█████████ | 264/293 [02:15<00:14,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  90%|█████████ | 265/293 [02:16<00:14,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  91%|█████████ | 266/293 [02:16<00:13,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  91%|█████████ | 267/293 [02:17<00:13,  1.94it/s]\u001b[A\n",
      "[Epoch 2]:  91%|█████████▏| 268/293 [02:17<00:12,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  92%|█████████▏| 269/293 [02:18<00:12,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  92%|█████████▏| 270/293 [02:18<00:11,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  92%|█████████▏| 271/293 [02:19<00:11,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  93%|█████████▎| 272/293 [02:19<00:10,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  93%|█████████▎| 273/293 [02:20<00:10,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  94%|█████████▎| 274/293 [02:20<00:09,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  94%|█████████▍| 275/293 [02:21<00:09,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  94%|█████████▍| 276/293 [02:21<00:08,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  95%|█████████▍| 277/293 [02:22<00:08,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  95%|█████████▍| 278/293 [02:22<00:07,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  95%|█████████▌| 279/293 [02:23<00:07,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  96%|█████████▌| 280/293 [02:23<00:06,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  96%|█████████▌| 281/293 [02:24<00:06,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  96%|█████████▌| 282/293 [02:24<00:05,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  97%|█████████▋| 283/293 [02:25<00:05,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  97%|█████████▋| 284/293 [02:25<00:04,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  97%|█████████▋| 285/293 [02:26<00:04,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  98%|█████████▊| 286/293 [02:27<00:03,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  98%|█████████▊| 287/293 [02:27<00:03,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  98%|█████████▊| 288/293 [02:28<00:02,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  99%|█████████▊| 289/293 [02:28<00:02,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  99%|█████████▉| 290/293 [02:29<00:01,  1.95it/s]\u001b[A\n",
      "[Epoch 2]:  99%|█████████▉| 291/293 [02:29<00:01,  1.95it/s]\u001b[A\n",
      "[Epoch 2]: 100%|█████████▉| 292/293 [02:30<00:00,  1.95it/s]\u001b[A\n",
      "[Epoch 2]: 100%|██████████| 293/293 [02:30<00:00,  1.95it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.6332 Acc: 0.6678\n"
     ]
    }
   ],
   "source": [
    "loss_train, acc_train, val_data = train(data_dir = data_d, label_dir = label_dir, save_dir = save_dir, epoch = epoch, mb = mb, num_class = num_class, num_workers = num_workers, use_cuda = cuda, conti = conti, lr = lr, save = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = os.path.join(save_dir, '{}.pt'.format('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_preloaded(7, use_cuda=cuda)\n",
    "model = model.load_state_dict(torch.load(modelpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg_preloaded(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, use_cuda):\n",
    "        super(vgg_preloaded, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.num_class = num_class\n",
    "        self.dtype = torch.cuda.FloatTensor if self.use_cuda else torch.FloatTensor\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        self.model = model.cuda() if self.use_cuda else model\n",
    "        self.model.classifier.require_grad = True\n",
    "        self.model.features.require_grad = True\n",
    "        \n",
    "\n",
    "    def forward(self, inp):\n",
    "        return(self.model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/293 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch 1]:   0%|          | 0/293 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch 1]:   0%|          | 1/293 [00:00<03:20,  1.46it/s]\u001b[A\n",
      "[Epoch 1]:   1%|          | 2/293 [00:01<02:57,  1.64it/s]\u001b[A\n",
      "[Epoch 1]:   1%|          | 3/293 [00:01<02:47,  1.73it/s]\u001b[A\n",
      "[Epoch 1]:   1%|▏         | 4/293 [00:02<02:42,  1.78it/s]\u001b[A\n",
      "[Epoch 1]:   2%|▏         | 5/293 [00:02<02:38,  1.81it/s]\u001b[A\n",
      "[Epoch 1]:   2%|▏         | 6/293 [00:03<02:36,  1.84it/s]\u001b[A\n",
      "[Epoch 1]:   2%|▏         | 7/293 [00:03<02:34,  1.86it/s]\u001b[A\n",
      "[Epoch 1]:   3%|▎         | 8/293 [00:04<02:32,  1.87it/s]\u001b[A\n",
      "[Epoch 1]:   3%|▎         | 9/293 [00:04<02:30,  1.88it/s]\u001b[A\n",
      "[Epoch 1]:   3%|▎         | 10/293 [00:05<02:29,  1.89it/s]\u001b[A\n",
      "[Epoch 1]:   4%|▍         | 11/293 [00:05<02:28,  1.90it/s]\u001b[A\n",
      "[Epoch 1]:   4%|▍         | 12/293 [00:06<02:27,  1.91it/s]\u001b[A\n",
      "[Epoch 1]:   4%|▍         | 13/293 [00:06<02:26,  1.91it/s]\u001b[A\n",
      "[Epoch 1]:   5%|▍         | 14/293 [00:07<02:25,  1.92it/s]\u001b[A\n",
      "[Epoch 1]:   5%|▌         | 15/293 [00:07<02:24,  1.92it/s]\u001b[A\n",
      "[Epoch 1]:   5%|▌         | 16/293 [00:08<02:23,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:   6%|▌         | 17/293 [00:08<02:22,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:   6%|▌         | 18/293 [00:09<02:22,  1.93it/s]\u001b[A\n",
      "[Epoch 1]:   6%|▋         | 19/293 [00:09<02:21,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:   7%|▋         | 20/293 [00:10<02:20,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:   7%|▋         | 21/293 [00:10<02:20,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:   8%|▊         | 22/293 [00:11<02:19,  1.94it/s]\u001b[A\n",
      "[Epoch 1]:   8%|▊         | 23/293 [00:11<02:18,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:   8%|▊         | 24/293 [00:12<02:18,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:   9%|▊         | 25/293 [00:12<02:17,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:   9%|▉         | 26/293 [00:13<02:16,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:   9%|▉         | 27/293 [00:13<02:16,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  10%|▉         | 28/293 [00:14<02:15,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  10%|▉         | 29/293 [00:14<02:15,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  10%|█         | 30/293 [00:15<02:14,  1.95it/s]\u001b[A\n",
      "[Epoch 1]:  11%|█         | 31/293 [00:15<02:14,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  11%|█         | 32/293 [00:16<02:13,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  11%|█▏        | 33/293 [00:16<02:12,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  12%|█▏        | 34/293 [00:17<02:12,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  12%|█▏        | 35/293 [00:17<02:11,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  12%|█▏        | 36/293 [00:18<02:11,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  13%|█▎        | 37/293 [00:18<02:10,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  13%|█▎        | 38/293 [00:19<02:10,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  13%|█▎        | 39/293 [00:19<02:09,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  14%|█▎        | 40/293 [00:20<02:09,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  14%|█▍        | 41/293 [00:20<02:08,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  14%|█▍        | 42/293 [00:21<02:07,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  15%|█▍        | 43/293 [00:21<02:07,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  15%|█▌        | 44/293 [00:22<02:06,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  15%|█▌        | 45/293 [00:22<02:06,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  16%|█▌        | 46/293 [00:23<02:05,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  16%|█▌        | 47/293 [00:23<02:05,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  16%|█▋        | 48/293 [00:24<02:04,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  17%|█▋        | 49/293 [00:24<02:04,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  17%|█▋        | 50/293 [00:25<02:03,  1.96it/s]\u001b[A\n",
      "[Epoch 1]:  17%|█▋        | 51/293 [00:25<02:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  18%|█▊        | 52/293 [00:26<02:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  18%|█▊        | 53/293 [00:26<02:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  18%|█▊        | 54/293 [00:27<02:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  19%|█▉        | 55/293 [00:27<02:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  19%|█▉        | 56/293 [00:28<02:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  19%|█▉        | 57/293 [00:28<02:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  20%|█▉        | 58/293 [00:29<01:59,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  20%|██        | 59/293 [00:29<01:58,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  20%|██        | 60/293 [00:30<01:58,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  21%|██        | 61/293 [00:31<01:57,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  21%|██        | 62/293 [00:31<01:57,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  22%|██▏       | 63/293 [00:32<01:56,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  22%|██▏       | 64/293 [00:32<01:56,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  22%|██▏       | 65/293 [00:33<01:55,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  23%|██▎       | 66/293 [00:33<01:55,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  23%|██▎       | 67/293 [00:34<01:54,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  23%|██▎       | 68/293 [00:34<01:54,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  24%|██▎       | 69/293 [00:35<01:53,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  24%|██▍       | 70/293 [00:35<01:53,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  24%|██▍       | 71/293 [00:36<01:52,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  25%|██▍       | 72/293 [00:36<01:52,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  25%|██▍       | 73/293 [00:37<01:51,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  25%|██▌       | 74/293 [00:37<01:51,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  26%|██▌       | 75/293 [00:38<01:50,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  26%|██▌       | 76/293 [00:38<01:50,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  26%|██▋       | 77/293 [00:39<01:49,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  27%|██▋       | 78/293 [00:39<01:49,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  27%|██▋       | 79/293 [00:40<01:48,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  27%|██▋       | 80/293 [00:40<01:48,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  28%|██▊       | 81/293 [00:41<01:47,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  28%|██▊       | 82/293 [00:41<01:47,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  28%|██▊       | 83/293 [00:42<01:46,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  29%|██▊       | 84/293 [00:42<01:46,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  29%|██▉       | 85/293 [00:43<01:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  29%|██▉       | 86/293 [00:43<01:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  30%|██▉       | 87/293 [00:44<01:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  30%|███       | 88/293 [00:44<01:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  30%|███       | 89/293 [00:45<01:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  31%|███       | 90/293 [00:45<01:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  31%|███       | 91/293 [00:46<01:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  31%|███▏      | 92/293 [00:46<01:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  32%|███▏      | 93/293 [00:47<01:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  32%|███▏      | 94/293 [00:47<01:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  32%|███▏      | 95/293 [00:48<01:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  33%|███▎      | 96/293 [00:48<01:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  33%|███▎      | 97/293 [00:49<01:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  33%|███▎      | 98/293 [00:49<01:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  34%|███▍      | 99/293 [00:50<01:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  34%|███▍      | 100/293 [00:50<01:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  34%|███▍      | 101/293 [00:51<01:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  35%|███▍      | 102/293 [00:51<01:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  35%|███▌      | 103/293 [00:52<01:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  35%|███▌      | 104/293 [00:52<01:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  36%|███▌      | 105/293 [00:53<01:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  36%|███▌      | 106/293 [00:53<01:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  37%|███▋      | 107/293 [00:54<01:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  37%|███▋      | 108/293 [00:54<01:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  37%|███▋      | 109/293 [00:55<01:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  38%|███▊      | 110/293 [00:55<01:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  38%|███▊      | 111/293 [00:56<01:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  38%|███▊      | 112/293 [00:56<01:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  39%|███▊      | 113/293 [00:57<01:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  39%|███▉      | 114/293 [00:57<01:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  39%|███▉      | 115/293 [00:58<01:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  40%|███▉      | 116/293 [00:58<01:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  40%|███▉      | 117/293 [00:59<01:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  40%|████      | 118/293 [00:59<01:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  41%|████      | 119/293 [01:00<01:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  41%|████      | 120/293 [01:00<01:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  41%|████▏     | 121/293 [01:01<01:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  42%|████▏     | 122/293 [01:01<01:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  42%|████▏     | 123/293 [01:02<01:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  42%|████▏     | 124/293 [01:02<01:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  43%|████▎     | 125/293 [01:03<01:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  43%|████▎     | 126/293 [01:03<01:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  43%|████▎     | 127/293 [01:04<01:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  44%|████▎     | 128/293 [01:04<01:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  44%|████▍     | 129/293 [01:05<01:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  44%|████▍     | 130/293 [01:05<01:22,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  45%|████▍     | 131/293 [01:06<01:22,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  45%|████▌     | 132/293 [01:06<01:21,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  45%|████▌     | 133/293 [01:07<01:21,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  46%|████▌     | 134/293 [01:07<01:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  46%|████▌     | 135/293 [01:08<01:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  46%|████▋     | 136/293 [01:08<01:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  47%|████▋     | 137/293 [01:09<01:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  47%|████▋     | 138/293 [01:09<01:18,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  47%|████▋     | 139/293 [01:10<01:18,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  48%|████▊     | 140/293 [01:10<01:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  48%|████▊     | 141/293 [01:11<01:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  48%|████▊     | 142/293 [01:11<01:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  49%|████▉     | 143/293 [01:12<01:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  49%|████▉     | 144/293 [01:13<01:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  49%|████▉     | 145/293 [01:13<01:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  50%|████▉     | 146/293 [01:14<01:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  50%|█████     | 147/293 [01:14<01:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  51%|█████     | 148/293 [01:15<01:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  51%|█████     | 149/293 [01:15<01:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  51%|█████     | 150/293 [01:16<01:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  52%|█████▏    | 151/293 [01:16<01:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  52%|█████▏    | 152/293 [01:17<01:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  52%|█████▏    | 153/293 [01:17<01:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  53%|█████▎    | 154/293 [01:18<01:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  53%|█████▎    | 155/293 [01:18<01:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  53%|█████▎    | 156/293 [01:19<01:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  54%|█████▎    | 157/293 [01:19<01:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  54%|█████▍    | 158/293 [01:20<01:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  54%|█████▍    | 159/293 [01:20<01:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  55%|█████▍    | 160/293 [01:21<01:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  55%|█████▍    | 161/293 [01:21<01:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  55%|█████▌    | 162/293 [01:22<01:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  56%|█████▌    | 163/293 [01:22<01:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  56%|█████▌    | 164/293 [01:23<01:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  56%|█████▋    | 165/293 [01:23<01:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  57%|█████▋    | 166/293 [01:24<01:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  57%|█████▋    | 167/293 [01:24<01:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  57%|█████▋    | 168/293 [01:25<01:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  58%|█████▊    | 169/293 [01:25<01:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  58%|█████▊    | 170/293 [01:26<01:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  58%|█████▊    | 171/293 [01:26<01:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  59%|█████▊    | 172/293 [01:27<01:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  59%|█████▉    | 173/293 [01:27<01:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  59%|█████▉    | 174/293 [01:28<01:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  60%|█████▉    | 175/293 [01:28<00:59,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  60%|██████    | 176/293 [01:29<00:59,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  60%|██████    | 177/293 [01:29<00:58,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  61%|██████    | 178/293 [01:30<00:58,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  61%|██████    | 179/293 [01:30<00:57,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  61%|██████▏   | 180/293 [01:31<00:57,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  62%|██████▏   | 181/293 [01:31<00:56,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  62%|██████▏   | 182/293 [01:32<00:56,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  62%|██████▏   | 183/293 [01:32<00:55,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  63%|██████▎   | 184/293 [01:33<00:55,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  63%|██████▎   | 185/293 [01:33<00:54,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  63%|██████▎   | 186/293 [01:34<00:54,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  64%|██████▍   | 187/293 [01:34<00:53,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  64%|██████▍   | 188/293 [01:35<00:53,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  65%|██████▍   | 189/293 [01:35<00:52,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  65%|██████▍   | 190/293 [01:36<00:52,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  65%|██████▌   | 191/293 [01:36<00:51,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  66%|██████▌   | 192/293 [01:37<00:51,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  66%|██████▌   | 193/293 [01:37<00:50,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  66%|██████▌   | 194/293 [01:38<00:50,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  67%|██████▋   | 195/293 [01:38<00:49,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  67%|██████▋   | 196/293 [01:39<00:49,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  67%|██████▋   | 197/293 [01:39<00:48,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  68%|██████▊   | 198/293 [01:40<00:48,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  68%|██████▊   | 199/293 [01:40<00:47,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  68%|██████▊   | 200/293 [01:41<00:47,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  69%|██████▊   | 201/293 [01:41<00:46,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  69%|██████▉   | 202/293 [01:42<00:46,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  69%|██████▉   | 203/293 [01:42<00:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  70%|██████▉   | 204/293 [01:43<00:45,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  70%|██████▉   | 205/293 [01:43<00:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  70%|███████   | 206/293 [01:44<00:44,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  71%|███████   | 207/293 [01:44<00:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  71%|███████   | 208/293 [01:45<00:43,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  71%|███████▏  | 209/293 [01:45<00:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  72%|███████▏  | 210/293 [01:46<00:42,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  72%|███████▏  | 211/293 [01:46<00:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  72%|███████▏  | 212/293 [01:47<00:41,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  73%|███████▎  | 213/293 [01:47<00:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  73%|███████▎  | 214/293 [01:48<00:40,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  73%|███████▎  | 215/293 [01:48<00:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  74%|███████▎  | 216/293 [01:49<00:39,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  74%|███████▍  | 217/293 [01:49<00:38,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  74%|███████▍  | 218/293 [01:50<00:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  75%|███████▍  | 219/293 [01:50<00:37,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  75%|███████▌  | 220/293 [01:51<00:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  75%|███████▌  | 221/293 [01:51<00:36,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  76%|███████▌  | 222/293 [01:52<00:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  76%|███████▌  | 223/293 [01:52<00:35,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  76%|███████▋  | 224/293 [01:53<00:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  77%|███████▋  | 225/293 [01:53<00:34,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  77%|███████▋  | 226/293 [01:54<00:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  77%|███████▋  | 227/293 [01:54<00:33,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  78%|███████▊  | 228/293 [01:55<00:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  78%|███████▊  | 229/293 [01:55<00:32,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  78%|███████▊  | 230/293 [01:56<00:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  79%|███████▉  | 231/293 [01:56<00:31,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  79%|███████▉  | 232/293 [01:57<00:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  80%|███████▉  | 233/293 [01:58<00:30,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  80%|███████▉  | 234/293 [01:58<00:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  80%|████████  | 235/293 [01:59<00:29,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  81%|████████  | 236/293 [01:59<00:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  81%|████████  | 237/293 [02:00<00:28,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  81%|████████  | 238/293 [02:00<00:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  82%|████████▏ | 239/293 [02:01<00:27,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  82%|████████▏ | 240/293 [02:01<00:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  82%|████████▏ | 241/293 [02:02<00:26,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  83%|████████▎ | 242/293 [02:02<00:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  83%|████████▎ | 243/293 [02:03<00:25,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  83%|████████▎ | 244/293 [02:03<00:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  84%|████████▎ | 245/293 [02:04<00:24,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  84%|████████▍ | 246/293 [02:04<00:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  84%|████████▍ | 247/293 [02:05<00:23,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  85%|████████▍ | 248/293 [02:05<00:22,  1.98it/s]\u001b[A\n",
      "[Epoch 1]:  85%|████████▍ | 249/293 [02:06<00:22,  1.98it/s]\u001b[A\n",
      "[Epoch 1]:  85%|████████▌ | 250/293 [02:06<00:21,  1.98it/s]\u001b[A\n",
      "[Epoch 1]:  86%|████████▌ | 251/293 [02:07<00:21,  1.98it/s]\u001b[A\n",
      "[Epoch 1]:  86%|████████▌ | 252/293 [02:07<00:20,  1.98it/s]\u001b[A\n",
      "[Epoch 1]:  86%|████████▋ | 253/293 [02:08<00:20,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  87%|████████▋ | 254/293 [02:08<00:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  87%|████████▋ | 255/293 [02:09<00:19,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  87%|████████▋ | 256/293 [02:09<00:18,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]:  88%|████████▊ | 257/293 [02:10<00:18,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  88%|████████▊ | 258/293 [02:10<00:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  88%|████████▊ | 259/293 [02:11<00:17,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  89%|████████▊ | 260/293 [02:11<00:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  89%|████████▉ | 261/293 [02:12<00:16,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  89%|████████▉ | 262/293 [02:12<00:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  90%|████████▉ | 263/293 [02:13<00:15,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  90%|█████████ | 264/293 [02:13<00:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  90%|█████████ | 265/293 [02:14<00:14,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  91%|█████████ | 266/293 [02:14<00:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  91%|█████████ | 267/293 [02:15<00:13,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  91%|█████████▏| 268/293 [02:15<00:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  92%|█████████▏| 269/293 [02:16<00:12,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  92%|█████████▏| 270/293 [02:16<00:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  92%|█████████▏| 271/293 [02:17<00:11,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  93%|█████████▎| 272/293 [02:17<00:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  93%|█████████▎| 273/293 [02:18<00:10,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  94%|█████████▎| 274/293 [02:18<00:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  94%|█████████▍| 275/293 [02:19<00:09,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  94%|█████████▍| 276/293 [02:19<00:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  95%|█████████▍| 277/293 [02:20<00:08,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  95%|█████████▍| 278/293 [02:20<00:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  95%|█████████▌| 279/293 [02:21<00:07,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  96%|█████████▌| 280/293 [02:21<00:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  96%|█████████▌| 281/293 [02:22<00:06,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  96%|█████████▌| 282/293 [02:22<00:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  97%|█████████▋| 283/293 [02:23<00:05,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  97%|█████████▋| 284/293 [02:23<00:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  97%|█████████▋| 285/293 [02:24<00:04,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  98%|█████████▊| 286/293 [02:24<00:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  98%|█████████▊| 287/293 [02:25<00:03,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  98%|█████████▊| 288/293 [02:25<00:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  99%|█████████▊| 289/293 [02:26<00:02,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  99%|█████████▉| 290/293 [02:26<00:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]:  99%|█████████▉| 291/293 [02:27<00:01,  1.97it/s]\u001b[A\n",
      "[Epoch 1]: 100%|█████████▉| 292/293 [02:27<00:00,  1.97it/s]\u001b[A\n",
      "[Epoch 1]: 100%|██████████| 293/293 [02:28<00:00,  1.98it/s]\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/293 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch 2]:   0%|          | 0/293 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.3366 Acc: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2]:   0%|          | 1/293 [00:00<03:12,  1.51it/s]\u001b[A\n",
      "[Epoch 2]:   1%|          | 2/293 [00:01<02:49,  1.72it/s]\u001b[A\n",
      "[Epoch 2]:   1%|          | 3/293 [00:01<02:41,  1.80it/s]\u001b[A\n",
      "[Epoch 2]:   1%|▏         | 4/293 [00:02<02:37,  1.83it/s]\u001b[A\n",
      "[Epoch 2]:   2%|▏         | 5/293 [00:02<02:34,  1.86it/s]\u001b[A\n",
      "[Epoch 2]:   2%|▏         | 6/293 [00:03<02:32,  1.88it/s]\u001b[A\n",
      "[Epoch 2]:   2%|▏         | 7/293 [00:03<02:31,  1.89it/s]\u001b[A\n",
      "[Epoch 2]:   3%|▎         | 8/293 [00:04<02:30,  1.90it/s]\u001b[A\n",
      "[Epoch 2]:   3%|▎         | 9/293 [00:04<02:28,  1.91it/s]\u001b[A\n",
      "[Epoch 2]:   3%|▎         | 10/293 [00:05<02:27,  1.91it/s]\u001b[AProcess Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 103, in __getitem__\n",
      "    return self.dataset[self.indices[idx]]\n",
      "  File \"/home/paperspace/projects/skin_cancer/Skin_Cancer_Detection/vgg_pretrained.py\", line 84, in __getitem__\n",
      "    image = self.transform(image)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 579, in __call__\n",
      "    return transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 232, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 562, in <lambda>\n",
      "    transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/functional.py\", line 491, in adjust_hue\n",
      "    img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 933, in convert\n",
      "    im = self.im.convert(mode, dither)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f44dcffcda0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 397, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 31623) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-211f1f2a8a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/skin_cancer/Skin_Cancer_Detection/vgg_pretrained.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, label_dir, save_dir, epoch, mb, num_class, num_workers, use_cuda, conti, lr, save, name, train_prop)\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_train, acc_train, val_data = train(data_dir = data_d, label_dir = label_dir, save_dir = save_dir, epoch = epoch, mb = mb, num_class = num_class, num_workers = num_workers, use_cuda = cuda, conti = conti, lr = lr, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
